{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"Frequency\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_colab:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import importlib\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_colab:\n",
    "    dir_path = (\n",
    "        \"drive/Othercomputers/my_computer/dl-nlp_project_named-entity-recognition/\"\n",
    "    )\n",
    "    # dir_path = \"drive/MyDrive/dl-nlp_project_named-entity-recognition/\"\n",
    "    module_path = dir_path.replace(\"/\", \".\")\n",
    "    # imports\n",
    "    data_module = importlib.import_module(module_path + \"data\")\n",
    "    load_data = data_module.load_data\n",
    "    extract_sentences_and_labels = data_module.extract_sentences_and_labels\n",
    "    generate_label_vocab = data_module.generate_label_vocab\n",
    "    split_data = data_module.split_data\n",
    "\n",
    "else:\n",
    "    dir_path = \"./\"\n",
    "    from data import (\n",
    "        load_data,\n",
    "        extract_sentences_and_labels,\n",
    "        generate_label_vocab,\n",
    "        split_data,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = dir_path + \"data/train.json\"\n",
    "test_file_path = dir_path + \"data/test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = load_data(train_file_path, test_file_path)\n",
    "train_sentences, train_raw_labels = extract_sentences_and_labels(train_data)\n",
    "test_sentences, test_raw_labels = extract_sentences_and_labels(test_data)\n",
    "\n",
    "# Generate label vocabulary\n",
    "label_vocab = generate_label_vocab(train_raw_labels + test_raw_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NumberAffected', 'PvalueDiff', 'TimePoint', 'SubGroupDescription', 'Drug', 'ConfIntervalDiff', 'AllocationRatio', 'MinAge', 'Country', 'ResultMeasuredValue', 'Frequency', 'DiffGroupAbsValue', 'ObservedResult', 'SdDevChangeValue', 'FinalNumPatientsArm', 'ConfIntervalChangeValue', 'Precondition', 'SdDevResValue', 'PercentageAffected', 'DoseDescription', 'PublicationYear', 'SdDevBL', 'ObjectiveDescription', 'RelativeChangeValue', 'ConclusionComment', 'Journal', 'DoseValue', 'PValueChangeValue', 'AvgAge', 'AggregationMethod', 'NumberPatientsArm', 'CTDesign', 'Author', 'NumberPatientsCT', 'PMID', 'Title', '<SPC>']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPECIAL_TOKEN = \"<SPC>\"\n",
    "\n",
    "\n",
    "class Labels:\n",
    "    def __init__(self, num_classes, names):\n",
    "        super().__init__()\n",
    "        self.names = names\n",
    "        print(self.names)\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __getitem__(self, label_vector):\n",
    "        return [self.names[idx] for idx, value in enumerate(label_vector) if value == 1]\n",
    "\n",
    "    def decode(self, label_vector):\n",
    "        return self.__getitem__(label_vector)\n",
    "\n",
    "    def encode(self, names):\n",
    "        indexes = []\n",
    "        for name in names:\n",
    "            index = self.names.index(name)\n",
    "            indexes.append(index)\n",
    "        tensor = torch.zeros(self.num_classes)\n",
    "        for index in indexes:\n",
    "            tensor[index] = 1\n",
    "        return tensor\n",
    "\n",
    "    def tensor2sentence(self, tensor):\n",
    "        return [self.decode(vector) for vector in tensor]\n",
    "\n",
    "\n",
    "ner_labels = Labels(\n",
    "    num_classes=len(label_vocab) + 1, names=label_vocab + [SPECIAL_TOKEN]\n",
    ")\n",
    "id2label = ner_labels.decode\n",
    "label2id = ner_labels.encode\n",
    "ner_labels.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentences(json_file_path):\n",
    "    with open(json_file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    sentences = []\n",
    "\n",
    "    for entry in data:\n",
    "        for sentence in entry[\"sentences\"]:\n",
    "            tokens = sentence[\"words\"]\n",
    "\n",
    "            entities = sentence[\"entities\"]\n",
    "            labels_list = [torch.zeros(ner_labels.num_classes) for x in tokens]\n",
    "            for label_entity in entities:\n",
    "                start_pos = label_entity[\"start_pos\"]\n",
    "                end_pos = label_entity[\"end_pos\"]\n",
    "                label = label_entity[\"label\"]\n",
    "                label_id = label2id([label]).argmax().item()\n",
    "                for label_index in range(start_pos, end_pos + 1):\n",
    "                    labels_list[label_index][label_id] = 1\n",
    "            sentence[\"tokens\"] = tokens\n",
    "            sentence[\"labels_list\"] = labels_list\n",
    "            sentences.append(sentence)\n",
    "\n",
    "    return [x[\"tokens\"] for x in sentences], [x[\"labels_list\"] for x in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300 1300\n",
      "145 145\n",
      "385 385\n"
     ]
    }
   ],
   "source": [
    "train_sentences, train_labels = extract_sentences(train_file_path)\n",
    "test_sentences, test_labels = extract_sentences(test_file_path)\n",
    "train_sentences, train_labels, val_sentences, val_labels = split_data(\n",
    "    train_sentences, train_labels\n",
    ")\n",
    "\n",
    "print(len(train_sentences), len(train_labels))\n",
    "print(len(val_sentences), len(val_labels))\n",
    "print(len(test_sentences), len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_name = f\"{dir_path}data/labels/{label}.json\"\n",
    "if os.path.exists(data_file_name):\n",
    "    with open(data_file_name, \"r\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "else:\n",
    "    data = {\n",
    "        \"sentences\": [],\n",
    "        \"labels_lists\": [],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_abbreviations = {\n",
    "    \"ObjectiveDescription\": \"OD\",\n",
    "    \"Precondition\": \"PC\",\n",
    "    \"RelativeChangeValue\": \"RCV\",\n",
    "    \"DiffGroupAbsValue\": \"DGAV\",\n",
    "    \"NumberPatientsCT\": \"NPC\",\n",
    "    \"AllocationRatio\": \"AR\",\n",
    "    \"DoseValue\": \"DV\",\n",
    "    \"AggregatonMethod\": \"AM\",\n",
    "    \"ResultMeasuredValue\": \"RMV\",\n",
    "    \"SdDevResValue\": \"SDRV\",\n",
    "    \"PvalueDiff\": \"PDiff\",\n",
    "    \"ConfIntervalChangeValue\": \"CICV\",\n",
    "    \"PValueChangeValue\": \"PVCV\",\n",
    "    \"ConfIntervalDiff\": \"CID\",\n",
    "    \"TimePoint\": \"TP\",\n",
    "    \"PercentageAffected\": \"PA\",\n",
    "    \"NumberAffected\": \"NA\",\n",
    "    \"SubGroupDescription\": \"SGD\",\n",
    "    \"MinAge\": \"MA\",\n",
    "    \"Frequency\": \"F\",\n",
    "    \"ObservedResult\": \"OR\",\n",
    "    \"SdDevChangeValue\": \"SDCV\",\n",
    "    \"FinalNumPatientsArm\": \"FNPA\",\n",
    "    \"DoseDescription\": \"DD\",\n",
    "    \"PublicationYear\": \"PY\",\n",
    "    \"SdDevBL\": \"SDBL\",\n",
    "    \"ConclusionComment\": \"CC\",\n",
    "    \"Journal\": \"J\",\n",
    "    \"AvgAge\": \"AA\",\n",
    "    \"AggregationMethod\": \"AM\",\n",
    "    \"NumberPatientsArm\": \"NPA\",\n",
    "    \"CTDesign\": \"CTD\",\n",
    "    \"Author\": \"A\",\n",
    "    \"Title\": \"T\",\n",
    "    \"Country\": \"C\",\n",
    "    \"Drug\": \"D\",\n",
    "}\n",
    "label_unabbreviations = {v: k for k, v in label_abbreviations.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "examples = []\n",
    "examples_with_labels = []\n",
    "for sentence, labels_list in zip(train_sentences, train_labels):\n",
    "    new_sentence = sentence\n",
    "    found = False\n",
    "    for i, (token, labels) in enumerate(zip(sentence, labels_list)):\n",
    "        if label in id2label(labels):\n",
    "            found = True\n",
    "            if not new_sentence[i].startswith(\"!!\"):\n",
    "                new_sentence[i] = f\"!!{token}!!\"\n",
    "    if found:\n",
    "        # print(\" \".join(new_sentence))\n",
    "        words = []\n",
    "        for word, labels in zip(sentence, labels_list):\n",
    "            # print(id2label(labels), word)\n",
    "            abbreviated_labels = [\n",
    "                label_abbreviations[label] if label in label_abbreviations else label\n",
    "                for label in id2label(labels)\n",
    "            ]\n",
    "            words.append(f\"{word} {abbreviated_labels}\")\n",
    "        # print(words)\n",
    "        # print()\n",
    "        examples.append(new_sentence)\n",
    "        examples_with_labels.append(words)\n",
    "\n",
    "print(len(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NumberPatientsCT'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_unabbreviations[\"NPC\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(input_str):\n",
    "    pattern = r\"!![^!]+!!|[-;/\\.]|\\w+|\\S\"\n",
    "    # Find all matches\n",
    "    tokens = re.findall(pattern, input_str)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_markdown_table(array, align: str = None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        array: The array to make into a table. Mush be a rectangular array\n",
    "               (constant width and height).\n",
    "        align: The alignment of the cells : 'left', 'center' or 'right'.\n",
    "    \"\"\"\n",
    "    # make sure every elements are strings\n",
    "    array = [[str(elt) for elt in line] for line in array]\n",
    "    # get the width of each column\n",
    "    widths = [max(len(line[i]) for line in array) for i in range(len(array[0]))]\n",
    "    # make every width at least 3 colmuns, because the separator needs it\n",
    "    widths = [max(w, 3) for w in widths]\n",
    "    # center text according to the widths\n",
    "    array = [[elt.center(w) for elt, w in zip(line, widths)] for line in array]\n",
    "\n",
    "    # separate the header and the body\n",
    "    array_head = array[0]\n",
    "    array = array[1:]\n",
    "\n",
    "    header = \"| \" + \" | \".join(array_head) + \" |\"\n",
    "\n",
    "    # alignment of the cells\n",
    "    align = str(align).lower()  # make sure `align` is a lowercase string\n",
    "    if align == \"none\":\n",
    "        # we are just setting the position of the : in the table.\n",
    "        # here there are none\n",
    "        border_left = \"| \"\n",
    "        border_center = \" | \"\n",
    "        border_right = \" |\"\n",
    "    elif align == \"center\":\n",
    "        border_left = \"|:\"\n",
    "        border_center = \":|:\"\n",
    "        border_right = \":|\"\n",
    "    elif align == \"left\":\n",
    "        border_left = \"|:\"\n",
    "        border_center = \" |:\"\n",
    "        border_right = \" |\"\n",
    "    elif align == \"right\":\n",
    "        border_left = \"| \"\n",
    "        border_center = \":| \"\n",
    "        border_right = \":|\"\n",
    "    else:\n",
    "        raise ValueError(\"align must be 'left', 'right' or 'center'.\")\n",
    "    separator = (\n",
    "        border_left + border_center.join([\"-\" * w for w in widths]) + border_right\n",
    "    )\n",
    "\n",
    "    # body of the table\n",
    "    body = [\"\"] * len(array)  # empty string list that we fill after\n",
    "    for idx, line in enumerate(array):\n",
    "        # for each line, change the body at the correct index\n",
    "        body[idx] = \"| \" + \" | \".join(line) + \" |\"\n",
    "    body = \"\\n\".join(body)\n",
    "\n",
    "    return header + \"\\n\" + separator + \"\\n\" + body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METHODS : In this randomized , open - label parallel study , !!twice!! !!-!! !!daily!! biphasic insulin aspart 30 ( 30 % soluble and 70 % protaminated insulin aspart ; BIAsp 30 ) plus metformin ( met ) was compared with !!once!! !!-!! !!daily!! insulin glargine ( glarg ) plus glimepiride ( glim ) in 255 insulin - na ï ve patients ( 131 male ; mean + / - SD age , 61 . 2 + / - 9 . 1 years ) .\n",
      "['METHODS []', ': []', 'In []', 'this []', 'randomized []', ', []', 'open []', '- []', 'label []', 'parallel []', 'study []', ', []', \"!!twice!! ['F']\", \"!!-!! ['F']\", \"!!daily!! ['F']\", 'biphasic []', 'insulin []', 'aspart []', '30 []', '( []', '30 []', '% []', 'soluble []', 'and []', '70 []', '% []', 'protaminated []', 'insulin []', 'aspart []', '; []', 'BIAsp []', '30 []', ') []', 'plus []', 'metformin []', '( []', 'met []', ') []', 'was []', 'compared []', 'with []', \"!!once!! ['F']\", \"!!-!! ['F']\", \"!!daily!! ['F']\", 'insulin []', 'glargine []', '( []', 'glarg []', ') []', 'plus []', 'glimepiride []', '( []', 'glim []', ') []', 'in []', \"255 ['NPC']\", 'insulin []', '- []', 'na []', 'ï []', 've []', 'patients []', '( []', '131 []', 'male []', '; []', 'mean []', '+ []', '/ []', '- []', 'SD []', 'age []', ', []', \"61 ['AA']\", \". ['AA']\", \"2 ['AA']\", '+ []', '/ []', '- []', '9 []', '. []', '1 []', 'years []', ') []', '. []']\n",
      "\n",
      "|     Word     | Labels (Abrv.) |        Labels        |\n",
      "|:------------ |:-------------- |:-------------------- |\n",
      "|   METHODS    |       []       |          []          |\n",
      "|      :       |       []       |          []          |\n",
      "|      In      |       []       |          []          |\n",
      "|     this     |       []       |          []          |\n",
      "|  randomized  |       []       |          []          |\n",
      "|      ,       |       []       |          []          |\n",
      "|     open     |       []       |          []          |\n",
      "|      -       |       []       |          []          |\n",
      "|    label     |       []       |          []          |\n",
      "|   parallel   |       []       |          []          |\n",
      "|    study     |       []       |          []          |\n",
      "|      ,       |       []       |          []          |\n",
      "|  !!twice!!   |     ['F']      |    ['Frequency']     |\n",
      "|    !!-!!     |     ['F']      |    ['Frequency']     |\n",
      "|  !!daily!!   |     ['F']      |    ['Frequency']     |\n",
      "|   biphasic   |       []       |          []          |\n",
      "|   insulin    |       []       |          []          |\n",
      "|    aspart    |       []       |          []          |\n",
      "|      30      |       []       |          []          |\n",
      "|      (       |       []       |          []          |\n",
      "|      30      |       []       |          []          |\n",
      "|      %       |       []       |          []          |\n",
      "|   soluble    |       []       |          []          |\n",
      "|     and      |       []       |          []          |\n",
      "|      70      |       []       |          []          |\n",
      "|      %       |       []       |          []          |\n",
      "| protaminated |       []       |          []          |\n",
      "|   insulin    |       []       |          []          |\n",
      "|    aspart    |       []       |          []          |\n",
      "|      ;       |       []       |          []          |\n",
      "|    BIAsp     |       []       |          []          |\n",
      "|      30      |       []       |          []          |\n",
      "|      )       |       []       |          []          |\n",
      "|     plus     |       []       |          []          |\n",
      "|  metformin   |       []       |          []          |\n",
      "|      (       |       []       |          []          |\n",
      "|     met      |       []       |          []          |\n",
      "|      )       |       []       |          []          |\n",
      "|     was      |       []       |          []          |\n",
      "|   compared   |       []       |          []          |\n",
      "|     with     |       []       |          []          |\n",
      "|   !!once!!   |     ['F']      |    ['Frequency']     |\n",
      "|    !!-!!     |     ['F']      |    ['Frequency']     |\n",
      "|  !!daily!!   |     ['F']      |    ['Frequency']     |\n",
      "|   insulin    |       []       |          []          |\n",
      "|   glargine   |       []       |          []          |\n",
      "|      (       |       []       |          []          |\n",
      "|    glarg     |       []       |          []          |\n",
      "|      )       |       []       |          []          |\n",
      "|     plus     |       []       |          []          |\n",
      "| glimepiride  |       []       |          []          |\n",
      "|      (       |       []       |          []          |\n",
      "|     glim     |       []       |          []          |\n",
      "|      )       |       []       |          []          |\n",
      "|      in      |       []       |          []          |\n",
      "|     255      |    ['NPC']     | ['NumberPatientsCT'] |\n",
      "|   insulin    |       []       |          []          |\n",
      "|      -       |       []       |          []          |\n",
      "|      na      |       []       |          []          |\n",
      "|      ï       |       []       |          []          |\n",
      "|      ve      |       []       |          []          |\n",
      "|   patients   |       []       |          []          |\n",
      "|      (       |       []       |          []          |\n",
      "|     131      |       []       |          []          |\n",
      "|     male     |       []       |          []          |\n",
      "|      ;       |       []       |          []          |\n",
      "|     mean     |       []       |          []          |\n",
      "|      +       |       []       |          []          |\n",
      "|      /       |       []       |          []          |\n",
      "|      -       |       []       |          []          |\n",
      "|      SD      |       []       |          []          |\n",
      "|     age      |       []       |          []          |\n",
      "|      ,       |       []       |          []          |\n",
      "|      61      |     ['AA']     |      ['AvgAge']      |\n",
      "|      .       |     ['AA']     |      ['AvgAge']      |\n",
      "|      2       |     ['AA']     |      ['AvgAge']      |\n",
      "|      +       |       []       |          []          |\n",
      "|      /       |       []       |          []          |\n",
      "|      -       |       []       |          []          |\n",
      "|      9       |       []       |          []          |\n",
      "|      .       |       []       |          []          |\n",
      "|      1       |       []       |          []          |\n",
      "|    years     |       []       |          []          |\n",
      "|      )       |       []       |          []          |\n",
      "|      .       |       []       |          []          |\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "index = random.randint(0, len(examples) - 1)\n",
    "print(\" \".join(examples[index]))\n",
    "print(examples_with_labels[index])\n",
    "print()\n",
    "original_table = []\n",
    "original_table.append([\"Word\", \"Labels (Abrv.)\", \"Labels\"])\n",
    "\n",
    "for labels_str in examples_with_labels[index]:\n",
    "    word = labels_str.split(\" \")[0]\n",
    "    labels = labels_str.split(\" \")[1]\n",
    "    label_list = ast.literal_eval(labels)\n",
    "    original_table.append(\n",
    "        [\n",
    "            word,\n",
    "            labels,\n",
    "            [\n",
    "                label_unabbreviations[label]\n",
    "                if label in label_unabbreviations\n",
    "                else label\n",
    "                for label in label_list\n",
    "            ],\n",
    "        ]\n",
    "    )\n",
    "print(make_markdown_table(original_table, align=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 :       METHODS       \n",
      " 1 :          :          , Suggestion: [], []\n",
      " 2 :       Patients      , Suggestion: [], []\n",
      " 3 :         with        , Suggestion: [], []\n",
      " 4 :         type        , Suggestion: [], []\n",
      " 5 :          2          , Suggestion: [], []\n",
      " 6 :       diabetes      , Suggestion: [], []\n",
      " 7 :          (          , Suggestion: [], []\n",
      " 8 :         HbA         , Suggestion: [], []\n",
      " 9 :          (          , Suggestion: [], []\n",
      "10 :          1c         , Suggestion: [], []\n",
      "11 :          )          , Suggestion: [], []\n",
      "12 :          6          , Suggestion: [], []\n",
      "13 :          .          , Suggestion: ['F'], ['Frequency']\n",
      "14 :          8          , Suggestion: ['F'], ['Frequency']\n",
      "15 :          -          , Suggestion: ['F'], ['Frequency']\n",
      "16 :          9          , Suggestion: [], []\n",
      "17 :          .          , Suggestion: [], []\n",
      "18 :          8          , Suggestion: [], []\n",
      "19 :          %          , Suggestion: [], []\n",
      "20 :          [          , Suggestion: [], []\n",
      "21 :          51         , Suggestion: [], []\n",
      "22 :          -          , Suggestion: [], []\n",
      "23 :          85         , Suggestion: [], []\n",
      "24 :         mmol        , Suggestion: [], []\n",
      "25 :          /          , Suggestion: [], []\n",
      "26 :         mol         , Suggestion: [], []\n",
      "27 :          ]          , Suggestion: [], []\n",
      "28 :          ,          , Suggestion: [], []\n",
      "29 :       fasting       , Suggestion: [], []\n",
      "30 :       glucose       , Suggestion: [], []\n",
      "31 :          <          , Suggestion: [], []\n",
      "32 :          16         , Suggestion: [], []\n",
      "33 :          .          , Suggestion: [], []\n",
      "34 :          5          , Suggestion: [], []\n",
      "35 :         mmol        , Suggestion: [], []\n",
      "36 :          /          , Suggestion: [], []\n",
      "37 :          l          , Suggestion: [], []\n",
      "38 :          ,          , Suggestion: [], []\n",
      "39 :       fasting       , Suggestion: [], []\n",
      "40 :        lipids       , Suggestion: [], []\n",
      "41 :          <          , Suggestion: [], []\n",
      "42 :          3          , Suggestion: ['F'], ['Frequency']\n",
      "43 :          .          , Suggestion: ['F'], ['Frequency']\n",
      "44 :          8          , Suggestion: ['F'], ['Frequency']\n",
      "45 :         mmol        , Suggestion: [], []\n",
      "46 :          /          , Suggestion: [], []\n",
      "47 :          l          , Suggestion: [], []\n",
      "48 :          ,          , Suggestion: [], []\n",
      "49 :         and         , Suggestion: [], []\n",
      "50 :         LDL         , Suggestion: [], []\n",
      "51 :          -          , Suggestion: [], []\n",
      "52 :     cholesterol     , Suggestion: [], []\n",
      "53 :          >          , Suggestion: [], []\n",
      "54 :          1          , Suggestion: [], []\n",
      "55 :          .          , Suggestion: [], []\n",
      "56 :          50         , Suggestion: ['NPC'], ['NumberPatientsCT']\n",
      "57 :         mmol        , Suggestion: [], []\n",
      "58 :          /          , Suggestion: [], []\n",
      "59 :          l          , Suggestion: [], []\n",
      "60 :          )          , Suggestion: [], []\n",
      "61 :      undergoing     , Suggestion: [], []\n",
      "62 :      treatment      , Suggestion: [], []\n",
      "63 :         with        , Suggestion: [], []\n",
      "64 :      lifestyle      , Suggestion: [], []\n",
      "65 :       changes       , Suggestion: [], []\n",
      "66 :          ,          , Suggestion: [], []\n",
      "67 :      glipizide      , Suggestion: [], []\n",
      "68 :          ,          , Suggestion: [], []\n",
      "69 :     pioglitazone    , Suggestion: [], []\n",
      "70 :          ,          , Suggestion: [], []\n",
      "71 :          or         , Suggestion: [], []\n",
      "72 :          a          , Suggestion: [], []\n",
      "73 :         mix         , Suggestion: [], []\n",
      "74 :          of         , Suggestion: ['AA'], ['AvgAge']\n",
      "75 :        these        , Suggestion: ['AA'], ['AvgAge']\n",
      "76 :          ,          , Suggestion: ['AA'], ['AvgAge']\n",
      "77 :         were        , Suggestion: [], []\n",
      "78 :       assigned      , Suggestion: [], []\n",
      "79 :          by         , Suggestion: [], []\n",
      "80 :          a          , Suggestion: [], []\n",
      "81 :       central       , Suggestion: [], []\n",
      "82 :        entity       , Suggestion: [], []\n",
      "83 :          to         , Suggestion: [], []\n",
      "84 :        either       , Suggestion: [], []\n",
      "85 :          4          , Suggestion: [], []\n",
      "86 :          .          \n",
      "87 :          00         \n",
      "88 :          g          \n",
      "89 :          /          \n",
      "90 :       !!day!!       \n",
      "91 :    rosiglitazone    \n",
      "92 :          (          \n",
      "93 :          n          \n",
      "94 :          =          \n",
      "95 :          30         \n",
      "96 :          )          \n",
      "97 :          or         \n",
      "98 :       placebo       \n",
      "99 :          (          \n",
      "100:          n          \n",
      "101:          =          \n",
      "102:          30         \n",
      "103:          )          \n",
      "104:         for         \n",
      "105:          11         \n",
      "106:        weeks        \n",
      "107:        across       \n",
      "108:         four        \n",
      "109:       clinical      \n",
      "110:       centers       \n",
      "111:          in         \n",
      "112:         the         \n",
      "113:          US         \n",
      "114:          .          \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Luis\\Documents\\Universität\\DL-NLP\\dl-nlp_project_named-entity-recognition\\augmentation.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Luis/Documents/Universit%C3%A4t/DL-NLP/dl-nlp_project_named-entity-recognition/augmentation.ipynb#X25sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m input_label \u001b[39m=\u001b[39m label_abbreviations[label] \u001b[39mif\u001b[39;00m label \u001b[39min\u001b[39;00m label_abbreviations \u001b[39melse\u001b[39;00m label\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Luis/Documents/Universit%C3%A4t/DL-NLP/dl-nlp_project_named-entity-recognition/augmentation.ipynb#X25sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mlen\u001b[39m(input_label) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Luis/Documents/Universit%C3%A4t/DL-NLP/dl-nlp_project_named-entity-recognition/augmentation.ipynb#X25sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     start_idx \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(\u001b[39minput\u001b[39;49m(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mStart idx for \u001b[39;49m\u001b[39m{\u001b[39;49;00minput_label\u001b[39m}\u001b[39;49;00m\u001b[39m: \u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Luis/Documents/Universit%C3%A4t/DL-NLP/dl-nlp_project_named-entity-recognition/augmentation.ipynb#X25sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     end_idx \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39minput\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEnd idx for \u001b[39m\u001b[39m{\u001b[39;00minput_label\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Luis/Documents/Universit%C3%A4t/DL-NLP/dl-nlp_project_named-entity-recognition/augmentation.ipynb#X25sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start_idx, end_idx \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "input_text = input(\"Input Sentence: \")\n",
    "token_list = tokenize(input_text.strip('\"'))\n",
    "labels_list = [[] for x in token_list]\n",
    "for i, token in enumerate(token_list):\n",
    "    suggesting = i < len(original_table) and 0 < i\n",
    "    if suggesting:\n",
    "        suggestion = f\", Suggestion: {original_table[i][1]}, {original_table[i][2]}\"\n",
    "        print(\n",
    "            f\"{i:^3}: {token:^20}{suggestion}\",\n",
    "        )\n",
    "    else:\n",
    "        print(f\"{i:^3}: {token:^20}\")\n",
    "table = []\n",
    "table.append([\"Id\", \"Word\", \"Labels\"])\n",
    "input_label = label_abbreviations[label] if label in label_abbreviations else label\n",
    "while len(input_label) > 0:\n",
    "    start_idx = int(input(f\"Start idx for {input_label}: \"))\n",
    "    end_idx = int(input(f\"End idx for {input_label}: \"))\n",
    "    for i in range(start_idx, end_idx + 1):\n",
    "        labels_list[i].append(\n",
    "            label_unabbreviations[input_label]\n",
    "            if input_label in label_unabbreviations\n",
    "            else input_label\n",
    "        )\n",
    "    input_label = input(\"Label: \")\n",
    "    while isinstance(input_label, int):\n",
    "        input_label = input(\"Label: \")\n",
    "\n",
    "token_list = [token.replace(\"!!\", \"\") for token in token_list]\n",
    "print(labels_list)\n",
    "for i, (token, labels) in enumerate(zip(token_list, labels_list)):\n",
    "    table.append([i, token, labels])\n",
    "print(make_markdown_table(table, align=\"left\"))\n",
    "submit = input(\"Hit enter to submit\")\n",
    "if len(submit) == 0:\n",
    "    data[\"sentences\"].append(token_list)\n",
    "    data[\"labels_lists\"].append(labels_list)\n",
    "    print(\"Data submitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/labels/ConfIntervalChangeValue.json was updated.\n"
     ]
    }
   ],
   "source": [
    "data_file_name = f\"{dir_path}data/labels/{label}.json\"\n",
    "with open(data_file_name, \"w\") as json_file:\n",
    "    json.dump(data, json_file, indent=2)\n",
    "    print(f\"{data_file_name} was updated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
