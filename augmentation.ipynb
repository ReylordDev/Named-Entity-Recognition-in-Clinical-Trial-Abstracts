{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_augment = \"PValueChangeValue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_colab:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import importlib\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_colab:\n",
    "    dir_path = (\n",
    "        \"drive/Othercomputers/my_computer/dl-nlp_project_named-entity-recognition/\"\n",
    "    )\n",
    "    # dir_path = \"drive/MyDrive/dl-nlp_project_named-entity-recognition/\"\n",
    "    module_path = dir_path.replace(\"/\", \".\")\n",
    "    # imports\n",
    "    data_module = importlib.import_module(module_path + \"data\")\n",
    "    load_data = data_module.load_data\n",
    "    extract_sentences_and_labels = data_module.extract_sentences_and_labels\n",
    "    generate_label_vocab = data_module.generate_label_vocab\n",
    "    split_data = data_module.split_data\n",
    "\n",
    "else:\n",
    "    dir_path = \"./\"\n",
    "    from data import (\n",
    "        load_data,\n",
    "        extract_sentences_and_labels,\n",
    "        generate_label_vocab,\n",
    "        split_data,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = dir_path + \"data/train.json\"\n",
    "test_file_path = dir_path + \"data/test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = load_data(train_file_path, test_file_path)\n",
    "train_sentences, train_raw_labels = extract_sentences_and_labels(train_data)\n",
    "test_sentences, test_raw_labels = extract_sentences_and_labels(test_data)\n",
    "\n",
    "# Generate label vocabulary\n",
    "label_vocab = generate_label_vocab(train_raw_labels + test_raw_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ConclusionComment', 'SdDevResValue', 'SdDevBL', 'PercentageAffected', 'NumberAffected', 'CTDesign', 'Journal', 'NumberPatientsArm', 'PValueChangeValue', 'ObjectiveDescription', 'ResultMeasuredValue', 'Frequency', 'ConfIntervalDiff', 'Country', 'PvalueDiff', 'MinAge', 'DiffGroupAbsValue', 'SdDevChangeValue', 'SubGroupDescription', 'AllocationRatio', 'Author', 'DoseValue', 'ObservedResult', 'AggregationMethod', 'DoseDescription', 'ConfIntervalChangeValue', 'PublicationYear', 'TimePoint', 'RelativeChangeValue', 'Precondition', 'Title', 'Drug', 'NumberPatientsCT', 'FinalNumPatientsArm', 'PMID', 'AvgAge', '<SPC>']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPECIAL_TOKEN = \"<SPC>\"\n",
    "\n",
    "\n",
    "class Labels:\n",
    "    def __init__(self, num_classes, names):\n",
    "        super().__init__()\n",
    "        self.names = names\n",
    "        print(self.names)\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __getitem__(self, label_vector):\n",
    "        return [self.names[idx] for idx, value in enumerate(label_vector) if value == 1]\n",
    "\n",
    "    def decode(self, label_vector):\n",
    "        return self.__getitem__(label_vector)\n",
    "\n",
    "    def encode(self, names):\n",
    "        indexes = []\n",
    "        for name in names:\n",
    "            index = self.names.index(name)\n",
    "            indexes.append(index)\n",
    "        tensor = torch.zeros(self.num_classes)\n",
    "        for index in indexes:\n",
    "            tensor[index] = 1\n",
    "        return tensor\n",
    "\n",
    "    def tensor2sentence(self, tensor):\n",
    "        return [self.decode(vector) for vector in tensor]\n",
    "\n",
    "\n",
    "ner_labels = Labels(\n",
    "    num_classes=len(label_vocab) + 1, names=label_vocab + [SPECIAL_TOKEN]\n",
    ")\n",
    "id2label = ner_labels.decode\n",
    "label2id = ner_labels.encode\n",
    "ner_labels.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentences(json_file_path):\n",
    "    with open(json_file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    sentences = []\n",
    "\n",
    "    for entry in data:\n",
    "        for sentence in entry[\"sentences\"]:\n",
    "            tokens = sentence[\"words\"]\n",
    "\n",
    "            entities = sentence[\"entities\"]\n",
    "            labels_list = [torch.zeros(ner_labels.num_classes) for x in tokens]\n",
    "            for label_entity in entities:\n",
    "                start_pos = label_entity[\"start_pos\"]\n",
    "                end_pos = label_entity[\"end_pos\"]\n",
    "                label = label_entity[\"label\"]\n",
    "                label_id = label2id([label]).argmax().item()\n",
    "                for label_index in range(start_pos, end_pos + 1):\n",
    "                    labels_list[label_index][label_id] = 1\n",
    "            sentence[\"tokens\"] = tokens\n",
    "            sentence[\"labels_list\"] = labels_list\n",
    "            sentences.append(sentence)\n",
    "\n",
    "    return [x[\"tokens\"] for x in sentences], [x[\"labels_list\"] for x in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300 1300\n",
      "145 145\n",
      "385 385\n"
     ]
    }
   ],
   "source": [
    "train_sentences, train_labels = extract_sentences(train_file_path)\n",
    "test_sentences, test_labels = extract_sentences(test_file_path)\n",
    "train_sentences, train_labels, val_sentences, val_labels = split_data(\n",
    "    train_sentences, train_labels\n",
    ")\n",
    "\n",
    "print(len(train_sentences), len(train_labels))\n",
    "print(len(val_sentences), len(val_labels))\n",
    "print(len(test_sentences), len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data initialized.\n"
     ]
    }
   ],
   "source": [
    "data_file_name = f\"{dir_path}data/labels/{label_to_augment}.json\"\n",
    "if os.path.exists(data_file_name):\n",
    "    with open(data_file_name, \"r\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "        print(f\"Data loaded from {data_file_name}\")\n",
    "else:\n",
    "    data = {\n",
    "        \"sentences\": [],\n",
    "        \"labels_lists\": [],\n",
    "    }\n",
    "    print(f\"New data initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_abbreviations = {\n",
    "    \"ObjectiveDescription\": \"OD\",\n",
    "    \"Precondition\": \"PC\",\n",
    "    \"RelativeChangeValue\": \"RCV\",\n",
    "    \"DiffGroupAbsValue\": \"DGAV\",\n",
    "    \"NumberPatientsCT\": \"NPC\",\n",
    "    \"AllocationRatio\": \"AR\",\n",
    "    \"DoseValue\": \"DV\",\n",
    "    \"AggregatonMethod\": \"AM\",\n",
    "    \"ResultMeasuredValue\": \"RMV\",\n",
    "    \"SdDevResValue\": \"SDRV\",\n",
    "    \"PvalueDiff\": \"PDIFF\",\n",
    "    \"ConfIntervalChangeValue\": \"CICV\",\n",
    "    \"PValueChangeValue\": \"PVCV\",\n",
    "    \"ConfIntervalDiff\": \"CID\",\n",
    "    \"TimePoint\": \"TP\",\n",
    "    \"PercentageAffected\": \"PA\",\n",
    "    \"NumberAffected\": \"NA\",\n",
    "    \"SubGroupDescription\": \"SGD\",\n",
    "    \"MinAge\": \"MA\",\n",
    "    \"Frequency\": \"F\",\n",
    "    \"ObservedResult\": \"OR\",\n",
    "    \"SdDevChangeValue\": \"SDCV\",\n",
    "    \"FinalNumPatientsArm\": \"FNPA\",\n",
    "    \"DoseDescription\": \"DD\",\n",
    "    \"PublicationYear\": \"PY\",\n",
    "    \"SdDevBL\": \"SDBL\",\n",
    "    \"ConclusionComment\": \"CC\",\n",
    "    \"Journal\": \"J\",\n",
    "    \"AvgAge\": \"AA\",\n",
    "    \"AggregationMethod\": \"AM\",\n",
    "    \"NumberPatientsArm\": \"NPA\",\n",
    "    \"CTDesign\": \"CTD\",\n",
    "    \"Author\": \"A\",\n",
    "    \"Title\": \"T\",\n",
    "    \"Country\": \"C\",\n",
    "    \"Drug\": \"D\",\n",
    "}\n",
    "label_unabbreviations = {v: k for k, v in label_abbreviations.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "examples = []\n",
    "examples_with_labels = []\n",
    "for sentence, labels_list in zip(train_sentences, train_labels):\n",
    "    new_sentence = sentence\n",
    "    found = False\n",
    "    for i, (token, labels) in enumerate(zip(sentence, labels_list)):\n",
    "        if label_to_augment in id2label(labels):\n",
    "            found = True\n",
    "            if not new_sentence[i].startswith(\"!!\"):\n",
    "                new_sentence[i] = f\"!!{token}!!\"\n",
    "    if found:\n",
    "        # print(\" \".join(new_sentence))\n",
    "        words = []\n",
    "        for word, labels in zip(sentence, labels_list):\n",
    "            # print(id2label(labels), word)\n",
    "            abbreviated_labels = [\n",
    "                label_abbreviations[label] if label in label_abbreviations else label\n",
    "                for label in id2label(labels)\n",
    "            ]\n",
    "            words.append(f\"{word} {abbreviated_labels}\")\n",
    "        # print(words)\n",
    "        # print()\n",
    "        examples.append(new_sentence)\n",
    "        examples_with_labels.append(words)\n",
    "\n",
    "print(len(examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(input_str):\n",
    "    pattern = r\"!![^!]+!!|[-;/\\.]|\\w+|\\S\"\n",
    "    # Find all matches\n",
    "    tokens = re.findall(pattern, input_str)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_markdown_table(array, align: str = None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        array: The array to make into a table. Mush be a rectangular array\n",
    "               (constant width and height).\n",
    "        align: The alignment of the cells : 'left', 'center' or 'right'.\n",
    "    \"\"\"\n",
    "    # make sure every elements are strings\n",
    "    array = [[str(elt) for elt in line] for line in array]\n",
    "    # get the width of each column\n",
    "    widths = [max(len(line[i]) for line in array) for i in range(len(array[0]))]\n",
    "    # make every width at least 3 colmuns, because the separator needs it\n",
    "    widths = [max(w, 3) for w in widths]\n",
    "    # center text according to the widths\n",
    "    array = [[elt.center(w) for elt, w in zip(line, widths)] for line in array]\n",
    "\n",
    "    # separate the header and the body\n",
    "    array_head = array[0]\n",
    "    array = array[1:]\n",
    "\n",
    "    header = \"| \" + \" | \".join(array_head) + \" |\"\n",
    "\n",
    "    # alignment of the cells\n",
    "    align = str(align).lower()  # make sure `align` is a lowercase string\n",
    "    if align == \"none\":\n",
    "        # we are just setting the position of the : in the table.\n",
    "        # here there are none\n",
    "        border_left = \"| \"\n",
    "        border_center = \" | \"\n",
    "        border_right = \" |\"\n",
    "    elif align == \"center\":\n",
    "        border_left = \"|:\"\n",
    "        border_center = \":|:\"\n",
    "        border_right = \":|\"\n",
    "    elif align == \"left\":\n",
    "        border_left = \"|:\"\n",
    "        border_center = \" |:\"\n",
    "        border_right = \" |\"\n",
    "    elif align == \"right\":\n",
    "        border_left = \"| \"\n",
    "        border_center = \":| \"\n",
    "        border_right = \":|\"\n",
    "    else:\n",
    "        raise ValueError(\"align must be 'left', 'right' or 'center'.\")\n",
    "    separator = (\n",
    "        border_left + border_center.join([\"-\" * w for w in widths]) + border_right\n",
    "    )\n",
    "\n",
    "    # body of the table\n",
    "    body = [\"\"] * len(array)  # empty string list that we fill after\n",
    "    for idx, line in enumerate(array):\n",
    "        # for each line, change the body at the correct index\n",
    "        body[idx] = \"| \" + \" | \".join(line) + \" |\"\n",
    "    body = \"\\n\".join(body)\n",
    "\n",
    "    return header + \"\\n\" + separator + \"\\n\" + body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A significant increase in serum folate and B12 levels ( 19 % and 17 . 3 % , !!p!! !!=!! !!0!! !!.!! !!000!! , respectively ) were observed in the folic acid group , whereas no significant changes occurred in the placebo group .\n",
      "\n",
      "|     Word     | Labels (Abrv.) |         Labels        |\n",
      "|:------------ |:-------------- |:--------------------- |\n",
      "|      A       |       []       |           []          |\n",
      "| significant  |       []       |           []          |\n",
      "|   increase   |       []       |           []          |\n",
      "|      in      |       []       |           []          |\n",
      "|    serum     |       []       |           []          |\n",
      "|    folate    |       []       |           []          |\n",
      "|     and      |       []       |           []          |\n",
      "|     B12      |       []       |           []          |\n",
      "|    levels    |       []       |           []          |\n",
      "|      (       |       []       |           []          |\n",
      "|      19      |       []       |           []          |\n",
      "|      %       |       []       |           []          |\n",
      "|     and      |       []       |           []          |\n",
      "|      17      |       []       |           []          |\n",
      "|      .       |       []       |           []          |\n",
      "|      3       |       []       |           []          |\n",
      "|      %       |       []       |           []          |\n",
      "|      ,       |       []       |           []          |\n",
      "|    !!p!!     |    ['PVCV']    | ['PValueChangeValue'] |\n",
      "|    !!=!!     |    ['PVCV']    | ['PValueChangeValue'] |\n",
      "|    !!0!!     |    ['PVCV']    | ['PValueChangeValue'] |\n",
      "|    !!.!!     |    ['PVCV']    | ['PValueChangeValue'] |\n",
      "|   !!000!!    |    ['PVCV']    | ['PValueChangeValue'] |\n",
      "|      ,       |       []       |           []          |\n",
      "| respectively |       []       |           []          |\n",
      "|      )       |       []       |           []          |\n",
      "|     were     |       []       |           []          |\n",
      "|   observed   |       []       |           []          |\n",
      "|      in      |       []       |           []          |\n",
      "|     the      |       []       |           []          |\n",
      "|    folic     |       []       |           []          |\n",
      "|     acid     |       []       |           []          |\n",
      "|    group     |       []       |           []          |\n",
      "|      ,       |       []       |           []          |\n",
      "|   whereas    |       []       |           []          |\n",
      "|      no      |     ['OR']     |   ['ObservedResult']  |\n",
      "| significant  |     ['OR']     |   ['ObservedResult']  |\n",
      "|   changes    |     ['OR']     |   ['ObservedResult']  |\n",
      "|   occurred   |       []       |           []          |\n",
      "|      in      |       []       |           []          |\n",
      "|     the      |       []       |           []          |\n",
      "|   placebo    |       []       |           []          |\n",
      "|    group     |       []       |           []          |\n",
      "|      .       |       []       |           []          |\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "index = random.randint(0, len(examples) - 1)\n",
    "print(\" \".join(examples[index]))\n",
    "# print(examples_with_labels[index])\n",
    "print()\n",
    "original_table = []\n",
    "original_table.append([\"Word\", \"Labels (Abrv.)\", \"Labels\"])\n",
    "\n",
    "for labels_str in examples_with_labels[index]:\n",
    "    word = labels_str.split(\" \")[0]\n",
    "    labels = labels_str.split(\" \")[1:]\n",
    "    label_list_str = \"\".join(labels).lstrip(\"['\").rstrip(\"']\")\n",
    "    label_list = (\n",
    "        [label_list_str] if label_list_str.isalpha() else label_list_str.split(\",\")\n",
    "    )\n",
    "    label_list = label_list if label_list != [\"\"] else []\n",
    "    if len(label_list) > 1:\n",
    "        for i, label in enumerate(label_list):\n",
    "            label_list[i] = label.strip(\"'\")\n",
    "    original_table.append(\n",
    "        [\n",
    "            word,\n",
    "            label_list,\n",
    "            [\n",
    "                label_unabbreviations[label]\n",
    "                if label in label_unabbreviations\n",
    "                else label\n",
    "                for label in label_list\n",
    "            ],\n",
    "        ]\n",
    "    )\n",
    "print(make_markdown_table(original_table, align=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 :         The         , Suggestion: [], []\n",
      " 1 :        folic        , Suggestion: [], []\n",
      " 2 :         acid        , Suggestion: [], []\n",
      " 3 :        group        , Suggestion: [], []\n",
      " 4 :      exhibited      , Suggestion: [], []\n",
      " 5 :          a          , Suggestion: [], []\n",
      " 6 :     significant     , Suggestion: [], []\n",
      " 7 :       upsurge       , Suggestion: [], []\n",
      " 8 :          in         , Suggestion: [], []\n",
      " 9 :        serum        , Suggestion: [], []\n",
      "10 :        folate       , Suggestion: [], []\n",
      "11 :         and         , Suggestion: [], []\n",
      "12 :         B12         , Suggestion: [], []\n",
      "13 :        levels       , Suggestion: [], []\n",
      "14 :          (          , Suggestion: [], []\n",
      "15 :          21         , Suggestion: [], []\n",
      "16 :          %          , Suggestion: [], []\n",
      "17 :         and         , Suggestion: [], []\n",
      "18 :          19         , Suggestion: ['PVCV'], ['PValueChangeValue']\n",
      "19 :          %          , Suggestion: ['PVCV'], ['PValueChangeValue']\n",
      "20 :          ,          , Suggestion: ['PVCV'], ['PValueChangeValue']\n",
      "21 :        !!p!!        , Suggestion: ['PVCV'], ['PValueChangeValue']\n",
      "22 :        !!=!!        , Suggestion: ['PVCV'], ['PValueChangeValue']\n",
      "23 :        !!0!!        , Suggestion: [], []\n",
      "24 :        !!.!!        , Suggestion: [], []\n",
      "25 :       !!0002!!      , Suggestion: [], []\n",
      "26 :          ,          , Suggestion: [], []\n",
      "27 :     respectively    , Suggestion: [], []\n",
      "28 :          )          , Suggestion: [], []\n",
      "29 :          ,          , Suggestion: [], []\n",
      "30 :       whereas       , Suggestion: [], []\n",
      "31 :         the         , Suggestion: [], []\n",
      "32 :       placebo       , Suggestion: [], []\n",
      "33 :        group        , Suggestion: [], []\n",
      "34 :        showed       , Suggestion: [], []\n",
      "35 :          no         , Suggestion: ['OR'], ['ObservedResult']\n",
      "36 :     significant     , Suggestion: ['OR'], ['ObservedResult']\n",
      "37 :       changes       , Suggestion: ['OR'], ['ObservedResult']\n",
      "38 :          .          , Suggestion: [], []\n",
      "[[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], ['PValueChangeValue'], ['PValueChangeValue'], ['PValueChangeValue'], ['PValueChangeValue'], ['PValueChangeValue'], [], [], [], [], [], [], [], [], [], ['ObservedResult'], ['ObservedResult'], ['ObservedResult'], []]\n",
      "\n",
      "|  Id |     Word     |         Labels        |\n",
      "|:--- |:------------ |:--------------------- |\n",
      "|  0  |     The      |           []          |\n",
      "|  1  |    folic     |           []          |\n",
      "|  2  |     acid     |           []          |\n",
      "|  3  |    group     |           []          |\n",
      "|  4  |  exhibited   |           []          |\n",
      "|  5  |      a       |           []          |\n",
      "|  6  | significant  |           []          |\n",
      "|  7  |   upsurge    |           []          |\n",
      "|  8  |      in      |           []          |\n",
      "|  9  |    serum     |           []          |\n",
      "|  10 |    folate    |           []          |\n",
      "|  11 |     and      |           []          |\n",
      "|  12 |     B12      |           []          |\n",
      "|  13 |    levels    |           []          |\n",
      "|  14 |      (       |           []          |\n",
      "|  15 |      21      |           []          |\n",
      "|  16 |      %       |           []          |\n",
      "|  17 |     and      |           []          |\n",
      "|  18 |      19      |           []          |\n",
      "|  19 |      %       |           []          |\n",
      "|  20 |      ,       |           []          |\n",
      "|  21 |      p       | ['PValueChangeValue'] |\n",
      "|  22 |      =       | ['PValueChangeValue'] |\n",
      "|  23 |      0       | ['PValueChangeValue'] |\n",
      "|  24 |      .       | ['PValueChangeValue'] |\n",
      "|  25 |     0002     | ['PValueChangeValue'] |\n",
      "|  26 |      ,       |           []          |\n",
      "|  27 | respectively |           []          |\n",
      "|  28 |      )       |           []          |\n",
      "|  29 |      ,       |           []          |\n",
      "|  30 |   whereas    |           []          |\n",
      "|  31 |     the      |           []          |\n",
      "|  32 |   placebo    |           []          |\n",
      "|  33 |    group     |           []          |\n",
      "|  34 |    showed    |           []          |\n",
      "|  35 |      no      |   ['ObservedResult']  |\n",
      "|  36 | significant  |   ['ObservedResult']  |\n",
      "|  37 |   changes    |   ['ObservedResult']  |\n",
      "|  38 |      .       |           []          |\n",
      "\n",
      "Data submitted\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "input_text = input(\"Input Sentence: \")\n",
    "token_list = tokenize(input_text.strip('\"'))\n",
    "labels_list = [[] for x in token_list]\n",
    "for i, token in enumerate(token_list):\n",
    "    suggesting = i + 1 < len(original_table) and 0 < i + 1\n",
    "    if suggesting:\n",
    "        suggestion = (\n",
    "            f\", Suggestion: {original_table[i + 1][1]}, {original_table[i + 1][2]}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"{i:^3}: {token:^20}{suggestion}\",\n",
    "        )\n",
    "    else:\n",
    "        print(f\"{i:^3}: {token:^20}\")\n",
    "table = []\n",
    "table.append([\"Id\", \"Word\", \"Labels\"])\n",
    "input_label = (\n",
    "    label_abbreviations[label_to_augment]\n",
    "    if label_to_augment in label_abbreviations\n",
    "    else label_to_augment\n",
    ")\n",
    "while len(input_label) > 0:\n",
    "    input_label = input_label.upper()\n",
    "    start_idx = input(f\"Start idx for {input_label}: \")\n",
    "    while start_idx.isalpha():\n",
    "        start_idx = input(f\"Start idx for {input_label}: \")\n",
    "    start_idx = int(start_idx)\n",
    "    end_idx = input(f\"End idx for {input_label}: \")\n",
    "    while end_idx.isalpha():\n",
    "        end_idx = input(f\"End idx for {input_label}: \")\n",
    "    end_idx = int(end_idx)\n",
    "    for i in range(start_idx, end_idx + 1):\n",
    "        labels_list[i].append(\n",
    "            label_unabbreviations[input_label]\n",
    "            if input_label in label_unabbreviations\n",
    "            else input_label\n",
    "        )\n",
    "    input_label = input(\"Label: \")\n",
    "    while input_label.isnumeric():\n",
    "        input_label = input(\"Label: \")\n",
    "\n",
    "token_list = [token.replace(\"!!\", \"\") for token in token_list]\n",
    "print(labels_list, end=\"\\n\\n\")\n",
    "for i, (token, labels) in enumerate(zip(token_list, labels_list)):\n",
    "    labels = list(set(labels))\n",
    "    table.append([i, token, labels])\n",
    "print(make_markdown_table(table, align=\"left\"))\n",
    "print()\n",
    "time.sleep(1)\n",
    "submit = input(\"Hit enter to submit\")\n",
    "if len(submit) == 0:\n",
    "    data[\"sentences\"].append(token_list)\n",
    "    data[\"labels_lists\"].append(labels_list)\n",
    "    print(\"Data submitted\")\n",
    "else:\n",
    "    print(\"Data not submitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/labels/PValueChangeValue.json was updated.\n"
     ]
    }
   ],
   "source": [
    "data_file_name = f\"{dir_path}data/labels/{label_to_augment}.json\"\n",
    "with open(data_file_name, \"w\") as json_file:\n",
    "    json.dump(data, json_file, indent=2)\n",
    "    print(f\"{data_file_name} was updated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
